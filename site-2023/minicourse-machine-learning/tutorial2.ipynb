{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## including libs\n",
    "\n",
    "!pip install tensorflow\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# baixando o dataset\n",
    "\n",
    "!wget https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip\n",
    "\n",
    "!unzip cats_and_dogs_filtered.zip\n",
    "\n",
    "!rm -rf cats_and_dogs_filtered.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### definindo o dataset\n",
    "\n",
    "## define o tamanho desejado para as imagens\n",
    "\n",
    "IMAGE_SHAPE = (224, 244)\n",
    "\n",
    "#define os diretorios para os dados de treinamento e validação\n",
    "\n",
    "TRAINING_DATA_DIR = 'cats_and_dogs_filtered/train/'\n",
    "VALID_DATA_DIR='cats_and_dogs_filtered/validation/'\n",
    "class_names = ['gato', 'cachorro']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparando o objeto para redimensionar os valores dos pixels das imagens entre 0 e 1\n",
    "\n",
    "datagen= tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rescale=1./255\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# criando conjuntos de dados de treinamento e validação a partir dos diretorios\n",
    "\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    TRAINING_DATA_DIR,\n",
    "    shuffle=True, #embaralha os dados de treinamento\n",
    "    target_size=IMAGE_SHAPE\n",
    ")\n",
    "\n",
    "valid_generator = datagen.flow_from_directory(\n",
    "    VALID_DATA_DIR,\n",
    "    shuffle=False, #embaralha os dados de treinamento\n",
    "    target_size=IMAGE_SHAPE#tamanho desejado das imagens\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotando algumas imagens do conjunto de treinamento\n",
    "\n",
    "def plot_dataset(dataset, num_images=5):\n",
    "  batch = dataset.next()\n",
    "\n",
    "  images = batch[0]\n",
    "  labels = batch[1]\n",
    "\n",
    "  random_indices = np.random.choice(len(images), num_images, replace=False)\n",
    "\n",
    "  for i, idx in enumerate(random_indices):\n",
    "    plt.subplot(1, num_images, i+1)\n",
    "    plt.imshow(images[idx])\n",
    "    plt.title(class_names[np.argmax(labels[idx])])\n",
    "    plt.axis('off')\n",
    "  plt.show\n",
    "plot_dataset(train_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## montando o modelo\n",
    "\n",
    "# Tamanho do lote (batch size) O número de amostras de dados processadas em cada iteração de treinamento.\n",
    "batch_size = 32\n",
    "# Épocas (epochs) - O número de vezes que o modelo passará por todo o conjunto de treinamento durante o treinamento.\n",
    "epochs = 10\n",
    "# Taxa de aprendizado (learning rate) Um hiperparâmetro que controla o quanto o modelo está aprendendo durante o treinamento.\n",
    "learning_rate= 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.src.layers.pooling.max_pooling1d import MaxPooling1D\n",
    "#define o modelo da rede neural\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(filters=8, kernel_size=(3,3), activation='relu',\n",
    "                           input_shape=(224, 224, 3)),#camada de convolução inicial\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2,2), strides=2), #canada de max pooling\n",
    "    tf.keras.layers.Conv2D(filters=16, kernel_size=(3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2,2), strides=2),\n",
    "    tf.keras.layers.Conv2D(filters=32, kernel_size=(3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2,2), strides=2),\n",
    "    tf.keras.layers.Flatten(), #camada de achatamento\n",
    "    tf.keras.layers.Dense(64, activation='relu'), #camada densa\n",
    "    tf.keras.layers.Dense(2, activation='softmax')#camada de saida\n",
    "\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile o modelo com otimizador, função de perda e metricas\n",
    "\n",
    "model.compile(\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate),\n",
    "    loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# treinamento\n",
    "\n",
    "# Tamanho do lote (batch size) - O número de amostras de dados processadas em cada iteração de treinamento.\n",
    "BATCH_SIZE = 32\n",
    "# Épocas (epochs) O número de vezes que o modelo passará por todo o conjunto de treinamento durante o treinamento.\n",
    "EPOCHS = 10\n",
    "# Taxa de aprendizado (learning rate) - Um hiperparâmetro que controla o quanto o modelo está aprendendo durante o treinamento.\n",
    "learning_rate= 0.0001\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definindo o histórico de treinamento para acompanhar o progresso do treinamento\n",
    "mc = ModelCheckpoint('model.h5', monitor='val_accuracy', mode='max', verbose=1, save_best_only=True)\n",
    "\n",
    "history = model.fit(train_generator,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    validation_data=valid_generator,\n",
    "                    callbacks=[mc],\n",
    "                    verbose=1)\n",
    "\n",
    "train_loss = history.history['loss']\n",
    "train_acc = history.history['accuracy']\n",
    "valid_loss = history.history['val_loss']\n",
    "valid_acc = history.history['val_accuracy']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para plotar as curvas de aprendizado\n",
    "def save_plots (train_acc, valid_acc, train_loss, valid_loss):\n",
    "plt.figure(figsize=(12, 9))\n",
    "plt.plot(train_acc, color='green', linestyle='-', label='train accuracy')\n",
    "plt.plot(valid_acc, color='blue', linestyle='-',\n",
    "label='validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.savefig('accuracy.png')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12, 9))\n",
    "\n",
    "/\n",
    "plt.plot(train_loss, color='orange', linestyle='-' label='train loss') plt.plot(valid_loss, color='red', linestyle='-', label='validation loss') plt.xlabel('Epochs')\n",
    "143\n",
    "plt.ylabel('Loss')\n",
    "144\n",
    "plt.legend ()\n",
    "145\n",
    "146\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
